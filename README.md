# Replication Package: Mining Software Defects: Should We Consider Affected Releases? [![DOI](https://zenodo.org/badge/DOI/10.5281/zenodo.2566774.svg)](https://doi.org/10.5281/zenodo.2549359)

**Authors:** Suraj Yatish (UofAdelaide), Jirayus Jiarpakdee (Monash), [Patanamon Thongtanunam (UniMelb)](http://patanamon.com), [Chakkrit Tantithamthavorn (Monash)](http://www.chakkrit.com)

**Contact:** chakkrit.tantithamthavorn@monash.edu

### Artifact Abstract

This artifact includes a collection of new benchmark defect datasets and R scripts for replicating our paper.
We are applying for REPLICATED badge with the following reasons: (1) our replication package is available at [GitHub (https://github.com/awsm-research/replication-icse2019)](https://github.com/awsm-research/replication-icse2019) and [Zenodo (https://zenodo.org/record/2549360#.XExDw88zaL8)](https://doi.org/10.5281/zenodo.2549359); (2) our defect datasets are available at [an Rnalytica R package](https://github.com/awsm-research/Rnalytica); (3) our replication package and defect datasets are reusable when ones wish to repeat the experiemnt with datasets from other domains and ecosystems; and (4) we believe that the main results of the paper are repeatable and replicable when using our provided defect datasets and R scripts. 
R programming knowledge is required to replicate the main results of our paper.


### Paper Abstract

With the rise of the Mining Software Repositories (MSR) field, defect datasets extracted from software repositories play a foundational role in many empirical studies related to software quality. At the core of defect data preparation is the identification of post-release defects. Prior studies leverage many heuristics (e.g., keywords and issue IDs) to identify post-release defects. However, such the heuristic approach is based on several assumptions, which pose common threats to the validity of many studies. In this paper, we set out to investigate the nature of the difference of defect datasets generated by the heuristic approach and the realistic approach that leverages the earliest affected release that is realistically estimated by a software development team for a given defect. In addition, we investigate the impact of defect identification approaches on the predictive accuracy and the ranking of defective modules that are produced by defect models. Through a case study of defect datasets of 32 releases, we find that that the heuristic approach has a large impact on both defect count datasets and binary defect datasets. Surprisingly, we find that the heuristic approach has a minimal impact on defect count models, suggesting that future work should not be too concerned about defect count models that are constructed using heuristic defect datasets. On the other hand, using defect datasets generated by the realistic approach lead to an improvement in the predictive accuracy of defect classification models.

## Installation guide (with Docker)

### Install Docker

### Download our Docker image

```bash
docker pull awsmdocker/rnalytica
git clone https://github.com/awsm-research/replication-icse2019/
cd replication-icse2019
```

### Enter the container
```
docker run -v `pwd`:/home/awsmdocker -it -w /home/awsmdocker awsmdocker/rnalytica
```

## Installation guide (without Docker)

### Prerequisites

- Unix-compatible OS (Linux or OS X)
- R 3.4 or higher (3.5.1 was used)
- At least 2Gb of RAM
- At least 1 CPU core (12 cores are preferable)
- Few hours of computational time for 12 cores
- Run the following command to install R (for Ubuntu).

### Install necessary softwares + check out the repository + install R libraries.

```bash
sudo apt-get install r-base libcurl4-gnutls-dev libcurl4-openssl-dev libssl-dev
git clone https://github.com/awsm-research/replication-icse2019/
cd replication-icse2019
Rscript install_libraries.R
```

## Replication guide 

### Step 1 - Produce results for RQ1.

```
Rscript RQ1-analysis.R
```

***Output:***

- `figures/figure4-a.pdf`
- `figures/figure4-b.pdf`
- `figures/figure5.pdf`
- `figures/figure8.pdf`


### Step 2 - Build defect models for RQ2 and RQ3. 

**Please note that this step takes few hours for 12 CPU cores. Thus, all of the resulting models are available [here](https://github.com/awsm-research/replication-icse2019/tree/master/models).**

```
Rscript RQ2-3-model-building.R
```

***Output:***

- `models/` all model results of defect models

### Step 3 - Run RQ2 and RQ3 analysis for defect count models

```
Rscript RQ2-3-analyze-defect-count-models.R
```

***Output:***

- `figures/figure6-a.pdf`
- `figures/figure7-a.pdf`
- `figures/figure9-a.pdf`

### Step 4 - Run RQ2 and RQ3 analysis for defect classification models

```
Rscript RQ2-3-analyze-defect-classification-models.R
```

***Output:***

- `figures/figure6-b.pdf`
- `figures/figure7-b.pdf`
- `figures/figure9-b.pdf`
